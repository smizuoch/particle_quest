{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3095fde",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 評価方法\n",
    "\n",
    "分類されていないデータを認識し、どれだけ正しくカテゴリごとに分類できるかを算出した「平均精度」の高さを競い合います。\n",
    "\n",
    "今回、活用するデータはLSWMD_25519となります。\n",
    "LSWMD_25519のFailureType項目が分類されていない状態のデータに対し、正しいFailureTypeカテゴリを分類するプログラムを作成し、その平均精度を算出します。\n",
    "平均精度とは、カテゴリごとに正しく分類できる精度を平均した値です。カテゴリごとに算出した精度（Aが正しく分類された数/Aのデータ数）を足し、カテゴリ数で割ります。\n",
    "\n",
    "公平な評価を実施するために、以下の制限を設けています。\n",
    "1. 外部パッケージをインストールするためのセルとsolution関数の中身のみを編集すること\n",
    "2. 校舎のiMac上で最後のセルの実行時間が15分未満であること　（%%timeitの出力結果を確認してください）\n",
    "\n",
    "※気になる点がある場合、Discordで気軽にお問合せください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b0f68e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # https://numpy.org/ja/\n",
    "import pandas as pd # https://pandas.pydata.org/\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea86471-32fa-46c6-a005-ad6e1f7b7f72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "外部パッケージを使用する場合、以下の方法でインストールを実施してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be8d1cd-7df7-4b10-aa1a-e24677b50d78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: keras in /opt/conda/lib/python3.11/site-packages (2.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: opencv-python in /opt/conda/lib/python3.11/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.11/site-packages (from opencv-python) (1.24.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow-cpu in /opt/conda/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow-cpu) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-cpu) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-cpu) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-cpu) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-cpu) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-cpu) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-cpu) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-cpu) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-cpu) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-cpu) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 必要な外部パッケージは、以下の内容を編集しインストールしてください\n",
    "!pip install keras\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113ea05-433a-4c82-9cb1-2c8f834a0364",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "以下のsolution関数のみ編集してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda6ad7e-8e26-4208-bdbd-3fa37e79c82c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solution(x_test_df, train_df):\n",
    "\timport numpy as np\n",
    "\tfrom keras.models import Sequential\n",
    "\tfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\tfrom keras.callbacks import EarlyStopping\n",
    "\tfrom sklearn.preprocessing import LabelEncoder\n",
    "\tfrom tensorflow.keras.utils import to_categorical\n",
    "\tfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\timport cv2  # OpenCV をインポート\n",
    "\tfrom tensorflow.keras.models import Model\n",
    "\tfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Attention\n",
    "\tfrom sklearn.model_selection import train_test_split\n",
    "\tfrom sklearn.linear_model import LinearRegression\n",
    "\tfrom sklearn.neighbors import KNeighborsClassifier\n",
    "\tfrom sklearn.decomposition import PCA\n",
    "\tfrom sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\theight, width = 43, 43 # 画像の幅と高さ\n",
    "\tchannels = 1\n",
    "\ttarget_size = (height, width)  # ターゲットサイズを (幅, 高さ) の順で設定\n",
    "\tinput_shape = (height, width, channels) # input shape を設定\n",
    "\ttrain_df, valid_df = train_test_split(train_df, stratify=train_df['failureType'], test_size=0.10, random_state=42)\n",
    "\n",
    "\tdef augment_images(images, labels):\n",
    "\t\t'''\n",
    "\t\t訓練用のデータの array (3d array) を受け取り, 要素である 2d array を基に拡張された 2d array を 3d array に詰め直して返す関数。\n",
    "\t\t新たにデータ拡張手法を追加したい場合は、以下の operations に lamda 関数を追加することで可能である。\n",
    "\t\t'''\n",
    "\t\toperations = [\n",
    "\t\t\t# 実行されるデータ拡張手法\n",
    "\t\t\tlambda x: x,\n",
    "\t\t\t# lambda x: cv2.rotate(x, cv2.ROTATE_90_CLOCKWISE),\n",
    "\t\t\t# lambda x: cv2.rotate(x, cv2.ROTATE_180),\n",
    "\t\t\t# lambda x: cv2.rotate(x, cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "\t\t\t# lambda x: cv2.flip(x, 0),\n",
    "\t\t\t# lambda x: cv2.flip(cv2.rotate(x, cv2.ROTATE_90_CLOCKWISE), 0),\n",
    "\t\t\t# lambda x: cv2.flip(cv2.rotate(x, cv2.ROTATE_180), 0),\n",
    "\t\t\t# lambda x: cv2.flip(cv2.rotate(x, cv2.ROTATE_90_COUNTERCLOCKWISE), 0)\n",
    "\t\t]\n",
    "\n",
    "\t\treturn np.array([operation(img) for img in images for operation in operations]).reshape(-1, height, width, channels), np.repeat(labels, len(operations), axis=0)\n",
    "\n",
    "\tdef cnn_predict(X_train, y_train, X_test, X_valid):\n",
    "\n",
    "\t\tencoder = LabelEncoder()\n",
    "\n",
    "\t\tencoded_Y = encoder.fit_transform(y_train)\n",
    "\t\ty_train = to_categorical(encoded_Y)\n",
    "\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinput_layer = Input(shape=input_shape)\n",
    "\t\t\n",
    "\t\t# 畳み込み層とプーリング層\n",
    "\t\tx = Conv2D(32, (5, 5), activation='relu')(input_layer)\n",
    "\t\tx = MaxPooling2D((2, 2))(x)\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\t\t\n",
    "\t\tx = Conv2D(32, (5, 5), activation='relu')(x)\n",
    "\t\tx = MaxPooling2D((2, 2))(x)\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\t\t\n",
    "\t\t# Attentionレイヤーの追加\n",
    "\t\tattention_output = Attention()([x, x])\n",
    "\t\t\n",
    "\t\t# Flattenレイヤーの追加\n",
    "\t\tx = Flatten()(attention_output)\n",
    "\t\t\n",
    "\t\t# 全結合層\n",
    "\t\tx = Dense(128, activation='relu')(x)\n",
    "\t\tx = Dropout(0.2)(x)\n",
    "\t\t\n",
    "\t\tx = Dense(64, activation='relu')(x)\n",
    "\t\tx = Dropout(0.2)(x)\n",
    "\t\t\n",
    "\t\toutput_layer = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "\t\t\n",
    "\t\t# モデルの定義\n",
    "\t\tmodel = Model(inputs=input_layer, outputs=output_layer)\n",
    "\t\t\n",
    "\t\tmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\t\t\n",
    "\t\tearly_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\t\t\n",
    "\t\t# 学習率を自動的に減らすコールバックを作成\n",
    "\t\treduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.01)\n",
    "\t\t\n",
    "\t\tmodel.fit(X_train, y_train, epochs=1, batch_size=64, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "\t\tX_test = np.array(X_test).reshape(-1, height, width, channels)\n",
    "\t\t\n",
    "\t\ty_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\t\t\n",
    "\t\tfirst_y_pred = np.argmax(model.predict(X_valid), axis=-1)\n",
    "\n",
    "\t\treturn encoder.inverse_transform(y_pred), encoder.inverse_transform(first_y_pred)\n",
    "\n",
    "\tdef knn_predict(X_train, y_train, X_test, X_valid):\n",
    "\n",
    "\t\tencoder = LabelEncoder()\n",
    "\n",
    "\t\tencoded_Y = encoder.fit_transform(y_train)\n",
    "\t\ty_train = to_categorical(encoded_Y)\n",
    "        \n",
    "\t\t#PCA次元削減\n",
    "\t\tpca = PCA(n_components=50)\n",
    "\t\tX_train_pca = pca.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "\t\t\n",
    "\t\t# kNN作成と訓練\n",
    "\t\tknn_model = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=20, metric='minkowski', p=2)\n",
    "\t\tknn_model.fit(X_train_pca, y_train)\n",
    "\t\t\n",
    "\t\tX_test_pca = pca.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\t\t\n",
    "\t\ty_pred = knn_model.predict(X_test_pca)\n",
    "\n",
    "\t\tX_valid_pca = pca.transform(X_valid.reshape(X_valid.shape[0], -1))\n",
    "\t\t\n",
    "\t\tfirst_y_pred = knn_model.predict(X_valid_pca)\n",
    "\t\t\n",
    "\t\treturn encoder.inverse_transform(y_pred), encoder.inverse_transform(first_y_pred)\n",
    "\n",
    "\t# メタモデルの作成\n",
    "\tdef meta_model_predict(stack_pred, y_valid, y_pred_1, y_pred_2):\n",
    "\n",
    "\t\tencoder = LabelEncoder()\n",
    "\n",
    "\t\tencoded_Y = encoder.fit_transform(y_valid)\n",
    "\t\ty_valid = to_categorical(encoded_Y)\n",
    "\t\t\n",
    "\t\tmeta_model = LinearRegression()\n",
    "\t\tmeta_model.fit(stack_pred, y_valid)\n",
    "\n",
    "\t\tstack_test_pred = np.column_stack((y_pred_1, y_pred_2))\n",
    "\t\tmeta_test_pred = meta_model.predict(stack_test_pred)\n",
    "\t\treturn meta_test_pred[0]\n",
    "\t\t# return encoder.inverse_transform(meta_test_pred[0])\n",
    "\t\t\n",
    "\t# オリジナルの画像をリサイズ\n",
    "\tresized_images = [cv2.resize(img, target_size[::-1], interpolation=cv2.INTER_LINEAR) for img in train_df['waferMap']]\n",
    "\tvalid_resized_images = [cv2.resize(img, target_size[::-1], interpolation=cv2.INTER_LINEAR) for img in valid_df['waferMap']]\n",
    "\tX_test = np.array([cv2.resize(img, target_size[::-1], interpolation=cv2.INTER_LINEAR) for img in x_test_df['waferMap']])\n",
    "\t\t\n",
    "\t# データ拡張 (ラベルもデータ拡張に合わせて増加)\n",
    "\tX_train, y_train = augment_images(resized_images, np.array(train_df['failureType']))\n",
    "\tX_valid, y_valid = augment_images(valid_resized_images, np.array(valid_df['failureType']))\n",
    "\tdel resized_images\n",
    "\tdel valid_resized_images\n",
    "\n",
    "\ty_pred_1, first_y_pred_1 = cnn_predict(X_train, y_train, X_test, X_valid)\n",
    "\ty_pred_2, first_y_pred_2 = knn_predict(X_train, y_train, X_test, X_valid)\n",
    "\n",
    "\tencoder = LabelEncoder()\n",
    "\n",
    "\tencoded_Y = encoder.fit_transform(first_y_pred_1)\n",
    "\tfirst_y_pred_1 = to_categorical(encoded_Y)\n",
    "\tencoded_Y = encoder.fit_transform(first_y_pred_2)\n",
    "\tfirst_y_pred_2 = to_categorical(encoded_Y)\n",
    "\tencoded_Y = encoder.fit_transform(y_pred_1)\n",
    "\ty_pred_1 = to_categorical(encoded_Y)\n",
    "\tencoded_Y = encoder.fit_transform(y_pred_2)\n",
    "\ty_pred_2 = to_categorical(encoded_Y)\n",
    "\n",
    "\tstack_pred = np.column_stack((first_y_pred_1,first_y_pred_2))\n",
    "\n",
    "\tmeta_test_pred = meta_model_predict(stack_pred, y_valid, y_pred_1, y_pred_2)\n",
    "\n",
    "\treturn pd.DataFrame({'failureType': encoder.inverse_transform(meta_test_pred)}, index=x_test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c20f4-f775-4d9d-90c7-a3b583584edd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "solution関数は以下のように活用され、平均精度を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a31dda-7c8b-477e-9547-5c9db739f7f0",
   "metadata": {
    "deletable": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 08:57:13.852585: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 12s 41ms/step - loss: 0.6786 - accuracy: 0.7476 - val_loss: 0.7927 - val_accuracy: 0.7192 - lr: 0.0010\n",
      "80/80 [==============================] - 1s 6ms/step\n",
      "72/72 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (2552, 8) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-r 1 -n 1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# データのインポート\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdf = pd.read_pickle(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../input/LSWMD_25519.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# テスト用と学習用のデータを作成（テストする際は、random_stateの値などを編集してみてください）\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mtrain_df, test_df = train_test_split(df, stratify=df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m], test_size=0.10, random_state=42)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43my_test_df = test_df[[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m]]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mx_test_df = test_df.drop(columns=[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# solution関数を実行\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43muser_result_df = solution(x_test_df, train_df)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43maverage_accuracy = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# ユーザーの提出物のフォーマット確認\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mif type(y_test_df) == type(user_result_df) and y_test_df.shape == user_result_df.shape:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # 平均精度の計算\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    accuracies = \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    for failure_type in df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m].unique():\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        y_test_df_by_failure_type = y_test_df[y_test_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m] == failure_type]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        user_result_df_by_failure_type = user_result_df[y_test_df[\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mfailureType\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m] == failure_type]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        matching_rows = (y_test_df_by_failure_type == user_result_df_by_failure_type).all(axis=1).sum()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        accuracies[failure_type] = matching_rows / len(y_test_df_by_failure_type)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        print(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m不良タイプ \u001b[39;49m\u001b[38;5;132;43;01m{failure_type}\u001b[39;49;00m\u001b[38;5;124;43m の正答率：\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43maccuracies[failure_type] * 100:.2f}\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    average_accuracy = sum(accuracies.values()) / len(accuracies)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mprint(f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m平均精度：\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43maverage_accuracy * 100:.2f}\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport matplotlib.pyplot as plt\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom sklearn.metrics import ConfusionMatrixDisplay\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mConfusionMatrixDisplay.from_predictions(y_test_df, user_result_df, xticks_rotation=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvertical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mplt.show()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2493\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2492\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2493\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2495\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/magics/execution.py:1189\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[1;32m   1191\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/timeit.py:208\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    206\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[0;32m--> 208\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:11\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 150\u001b[0m, in \u001b[0;36msolution\u001b[0;34m(x_test_df, train_df)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m valid_resized_images\n\u001b[1;32m    149\u001b[0m y_pred_1, first_y_pred_1 \u001b[38;5;241m=\u001b[39m cnn_predict(X_train, y_train, X_test, X_valid)\n\u001b[0;32m--> 150\u001b[0m y_pred_2, first_y_pred_2 \u001b[38;5;241m=\u001b[39m \u001b[43mknn_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m    154\u001b[0m encoded_Y \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(first_y_pred_1)\n",
      "Cell \u001b[0;32mIn[3], line 120\u001b[0m, in \u001b[0;36msolution.<locals>.knn_predict\u001b[0;34m(X_train, y_train, X_test, X_valid)\u001b[0m\n\u001b[1;32m    116\u001b[0m X_valid_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_valid\u001b[38;5;241m.\u001b[39mreshape(X_valid\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    118\u001b[0m first_y_pred \u001b[38;5;241m=\u001b[39m knn_model\u001b[38;5;241m.\u001b[39mpredict(X_valid_pca)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m, encoder\u001b[38;5;241m.\u001b[39minverse_transform(first_y_pred)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:153\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform labels back to original encoding.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    Original encoding.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 153\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# inverse transform of empty array is empty array\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1244\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1234\u001b[0m             (\n\u001b[1;32m   1235\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1244\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1246\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (2552, 8) instead."
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "\n",
    "# データのインポート\n",
    "df = pd.read_pickle(\"../input/LSWMD_25519.pkl\")\n",
    "\n",
    "# テスト用と学習用のデータを作成（テストする際は、random_stateの値などを編集してみてください）\n",
    "train_df, test_df = train_test_split(df, stratify=df['failureType'], test_size=0.10, random_state=42)\n",
    "\n",
    "y_test_df = test_df[['failureType']]\n",
    "x_test_df = test_df.drop(columns=['failureType'])\n",
    "\n",
    "# solution関数を実行\n",
    "user_result_df = solution(x_test_df, train_df)\n",
    "\n",
    "average_accuracy = 0\n",
    "# ユーザーの提出物のフォーマット確認\n",
    "if type(y_test_df) == type(user_result_df) and y_test_df.shape == user_result_df.shape:\n",
    "    # 平均精度の計算\n",
    "    accuracies = {}\n",
    "    for failure_type in df['failureType'].unique():\n",
    "        y_test_df_by_failure_type = y_test_df[y_test_df['failureType'] == failure_type]\n",
    "        user_result_df_by_failure_type = user_result_df[y_test_df['failureType'] == failure_type]\n",
    "        matching_rows = (y_test_df_by_failure_type == user_result_df_by_failure_type).all(axis=1).sum()\n",
    "        accuracies[failure_type] = matching_rows / len(y_test_df_by_failure_type)\n",
    "        print(f\"不良タイプ {failure_type} の正答率：{accuracies[failure_type] * 100:.2f}%\")\n",
    "    \n",
    "    average_accuracy = sum(accuracies.values()) / len(accuracies)\n",
    "\n",
    "print(f\"平均精度：{average_accuracy * 100:.2f}%\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_test_df, user_result_df, xticks_rotation=\"vertical\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
